### 概述

一个 Flink 作业，从 Client 端提交到最后真正调度执行，执行图会经过下面四个阶段：

* StreamGraph：根据编写的代码生成的最初的图，它表示程序的拓扑结构。
* JobGraph：优化 StreamGraph，将多个符合条件的节点 chain 在一起作为一个 JobVertex。是提交给 JobManager 的数据结构。

* ExecutionGraph：JobGraph 的并行化版本，Flink 调度时依赖的核心数据结构。
* 物理执行图：在各个 TaskManager 上部署 Task 后形成的一张虚拟图，不是一个具体的数据结构。

<img src="/Users/licheng/Documents/Typora/Picture/QQ截图20200513142543.png" alt="QQ截图20200513142543" style="zoom: 75%;" />

### StreamGraph

这一部分主要在 `StreamGraphGenerator#generate(env,transformations)` 方法中完成的。

* 首先将 transformation 添加到 transformations 集合中。
* 然后遍历 transformations，调用 `transform()` 方法根据 transformation 类型创建相应的 StreamNode。
* 添加 StreamEdge 连接上游的 StreamNode。根据上下游 StreamNode 并发度不同，StreamEdge 上的分区函数可以分为 Rebalance、Shuffle、Forward。

对逻辑转换 (partition、union等) 不会生成具体的 StreamNode 和 StreamEdge，而是添加一个虚节点。当 partition 的下游 transform 添加 StreamEdge 时，会把 partition 信息写入到 StreamEdge 中。

#### 关键参数

* StreamNode：用来代表 operator 的类，其关键成员变量有 slotSharingGroup、jobVertexClass、inEdges、outEdges 以及 transformationUID；
* StreamEdge：是用来描述两个 operator 逻辑的连接边，其关键变量有 sourceVertex、targetVertex。

### JobGraph

这一部分主要是在 `StreamingJobGraphGenerator(streamGraph,jobID)#createJobGraph()` 方法中完成的。

* 设置调度模式。Eager，在作业启动时申请资源将所有的 Task 调度起来。Lazy From Source，从 Source 开始，按拓扑顺序来进行调度。默认是 Eager。
* 广度优先遍历 StreamGraph，为每个 streamNode 生成 byte 数组类型的 hash 值。
* 从 source 节点开始递归寻找嵌到一起的 operator。不能嵌到一起的节点单独生成 JobVertex；能够嵌到一起的开始节点生成 JobVertex，其他节点以序列化的形式写入到 StreamConfig，然后合并到 `CHAINED_TASK_CONFIG`，再通过 JobEdge 连接上下游 JobVertex。
* 将每个 JobVertex 的入边 (StreamEdge) 序列化到该 StreamConfig。
* 根据 GroupName 为每个 JobVertext 指定 SlotSharingGroup。
* 配置 Checkpoint。
* 设置 ExecutionConfig。

#### 为什么要生成 hash 值

Flink 任务失败的时候，各个 operator 是能够从 checkpoint 中恢复到失败之前的状态的，恢复的时候是依据 JobVertexID (hash 值) 进行状态恢复的。相同的任务在恢复的时候要求 operator 的 hash 值不变，因此能够获取对应的状态。

StreamNodeId 是一个从 0 开始的累加值 (从前往后，每个 StreamNode 的 id 值逐渐 + 1)，同样的 Job 可能会得到不一样的 id，所以不能作为故障恢复的标识。

#### 构建 Operator Chain 的条件

* 上下游节点的操作符都不为 null 且下游节点只有一个输入。
* 上下游节点在一个 SlotSharingGroup 内且并行度相等。
* 上游节点的连接策略是 HEAD 或者 ALWAYS，下游节点的连接策略是 ALWAYS。
* StreamEdge 的分区函数是 ForwardPartitioner 的实例。
* 可以进行节点连接操作。

#### 构建 Operator Chain 的过程

这一部分主要是在 `setChaining() ` 方法中完成的。

* 首先遍历 StreamGraph 的 SourceNode，然后选择从 SourceNode 开始递归执行 `createChain()` 方法。

* `createChain()` 方法首先会分析当前节点的出边，然后根据构建 Operator Chain 的条件，将出边分成` chainable`和 `noChainable` 两类，并分别递归调用自身方法。如果是 chainable 就将 chainIndex + 1，startNodeId 不变；否则将 chainIndex 置为 0。

* 然后会将 StreamNode 中的配置信息序列化到 StreamConfig 中。

  如果当前节点不是 Chain 中的子节点，则会直接构建 JobVertex。如果是 Chain 中的子节点，则会将 StreamConfig 添加到该 Chain 的 chainConfigs Map 集合中。一个 Operator Chain，除了头结点会生成对应的 JobVertex，其余节点都是以序列化的形式写入到 StreamConfig 中，并保存到头结点的 `CHAINED_TASK_CONFIG` 配置项中。直到部署时，才会取出并生成对应的 Chain Operators。

* 将每个 JobVertex 的出边写入到 StreamConfig 中。

* 添加 IntermediateDataSet，作为 JobVertex 的输出结果集。通过 StreamEdge 构建 JobEdge，连接 JobVertex 和 IntermediateDateSet。

#### 构建 Operator Chain 的好处

构建 Operator Chain 后流内的数据不会经过序列化/反序列化、网络传输，而是直接将消息对象传递给下游的 ChainOperator 处理，这样能减少消息的序列化/反序列化、网络传输的消耗。并且每个 subTask 在一个线程中执行。形成 Operator Chain 后能减少线程之间的切换。

可以通过调用`startNewChain()`来开始一个新的 Chain。或者调用`disableChaining()`来指示该 Operator 不参与 Chaining。因为某些计算可能需要资源比较多，形成 Operator Chain 可能会导致执行时间过长，通过禁用 Chaining 可以让该过程独享整个计算资源。

#### 关键参数

* JobVertex：符合条件的多个 StreamNode 可能会 Chain 在一起生成一个 JobVertex。
* IntermediateDataSet：表示 JobVertex 的输出，即经过 Operator 处理产生的中间数据集。
* JobEdge：代表了 JobGraph 中的一条数据传输通道。Source 是 IntermediateDataSet，Target 是 JobVertex。
* StreamConfig：主要是将 StreamGraph 中的 StreamNode 的详细信息同步到它对应的 StreamConfig 对象中。记录内容是 Operator 的配置信息。每个 JobVertex 都会对应一个可序列化的 StreamConfig，用来发送给 JobManager 和 TaskManager。最后在 TaskManager 中运行 Task 时，需要从这里面反序列化出所需要的配置信息，其中就包括了含有用户代码的 Operator。
* `Map<Integer, Map<Integer, StreamConfig>> chainedConfigs`：Operator Chain Config，第一个 Integer 表示 StartNodeId，第二个 Integer 表示 StreamNodeId。即表示每个 Operator Chain 包含的 StreamNode 配置信息。

### ExecutionGraph

这一部分主要是在 `ExecutionGraphBuilder#buildGraph()` 方法中实现的。

* 将 JobGraph 里面的 JobVertex 从 Source 节点开始拓扑排序。
* 调用 `attachJobGraph()` 方法，根据拓扑排序结果，由 JobVertex 构建 ExecutionJobVertex；由 IntermediateDataSet 构建 IntermediateResult；根据 jobVertex 并发度构建 ExecutionVertex、IntermediateResultPartition；根据 JobEdge 构建 ExecutionEdge 连接 ExecutionVertex 与 IntermediateResultPartition。

#### 关键参数

* ExecutionJobVertex：和 JobGraph 中的 JobVertex 一一对应。每一个 ExecutionJobVertex 都有一个或多个 ExecutionVertex (与并行度有关)。
* ExecutionVertex：表示 ExecutionJobVertex 的其中一个子任务，输入是 ExecutionEdge，输出是 IntermediateResultPartition。
* IntermediateResult：和 JobGraph 中的 IntermediateDataSet 一一对应。一个 IntermediateResult 包含多个IntermediateResultPartition (与并行度有关)。
* IntermediateResultPartition：表示 ExecutionVertex 的一个输出分区，Producer 是 ExecutionVertex，Consumer 是若干个ExecutionEdge。
* ExecutionEdge：连接 IntermediateResultPartition 和 ExecutionVertex 的管道，Source 是 IntermediateResultPartition，Target 是 ExecutionVertex。Source 和 Target 都只能是一个。

### 物理执行计划

按照拓扑顺序为所有的 `ExecutionJobVertex` 分配资源，其中每一个 `ExecutionVertex` 都需要分配一个 slot，`ExecutionVertex` 的一次执行对应一个 `Execution`，在分配资源的时候会依照 `SlotSharingGroup` 和 `CoLocationConstraint` 确定，分配的时候会考虑 slot 重用的情况。

在所有的节点资源都获取成功后，会逐一调用 `Execution.deploy()` 来部署 `Execution`, 使用 `TaskDeploymentDescriptor` 来描述 `Execution`，并提交到分配给该 Execution 的 slot 对应的 TaskManager, 最终被分配给对应的 `TaskExecutor` 执行。