### 消息语义

* At least once：消息绝不会丢，但可能会重复传输。数据处理完成后再提交 offset。
* At most once：消息可能会丢，但绝不会重复传输。发送数据后就提交 offset。
* Exactly once：每条消息肯定会被传输一次且仅传输一次。同时提交数据和 offset。

### 幂等性

Producer 的幂等性指的是当发送同一条消息时，数据在 Server 端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：

* 只能保证 Producer 在单个会话内不丟不重，如果 Producer 出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）;
* 幂等性不能跨多个 Topic-Partition，只能保证单个 partition 内的幂等性，当涉及多个 Topic-Partition 时，这中间的状态并没有同步。

如果需要跨会话、跨多个 Topic-partition 的情况，需要使用 Kafka 的事务性来实现。

#### 幂等性实现原理

每个 Producer 在初始化时都会被分配一个唯一的 PID，并且 Producer 在发送数据时，将会给每条消息标识一个 sequence number，从 0 开始自增。Broker 对于每一个 Topic-partition 也会维护一个 sequence number，对于接收的每条消息，如果其序号比 Broker 缓存的序号大 1，则 Broker 会接受它，否则将其丢弃。

> Producer 重启后 PID 会重新分配，所以 Producer 无法做到跨会话幂等。
>
> 如果消息序号比 Broker 维护的序号大一以上，说明中间有数据尚未写入，也即乱序，此时 Broker 拒绝该消息，Producer 抛出 InvalidSequenceNumber。
>
> 如果消息序号小于等于 Broker 维护的序号，说明该消息已被保存，即为重复消息，Broker 直接丢弃该消息，Producer 抛出 DuplicateSequenceNumber。

### 事务性

#### 事务性实现原理

利用 2PC 协议，Producer 在开始一个事务时，告诉  TransactionCoordinator 事务开始，然后开始向多个 Topic-Partition 写如数据，当收到所有消息的确认后，Producer 向 TransactionCoordinator 发送 commit 请求，然后事务真正提交。如果中间出现异常，那么事务将会被 abort。

TransactionCoordinator 是用来管理事务相关的状态信息的。它会将对应事务数据写入到`__transaction_state` 这个内部 Topic 中，保证事务状态信息的容错性与一致性。

Kafka 在 Producer 端引入了一个全局唯一的 TransactionId，保证跨会话的数据幂等发送，且事务失败后能够重新开始事务。

#### 事务性流程

<img src="C:\Users\admin\Typora\Picture\image-20200704200412874.png" alt="image-20200704200412874" style="zoom:67%;" />

##### 寻找 Transaction Coordinator 服务地址

Producer 会首先从 Kafka 集群中选择任意一台机器，然后向其发送请求，获取 Transaction Coordinator 服务的地址。

Kafka 有个特殊的事务 Topic，名称为`__transaction_state`，负责持久化事务消息。这个 Topic 默认有 50 个分区，每个分区负责一部分事务。事务划分是根据 transaction id 计算出该事务属于哪个分区。这个分区的 leader 所在的机器，就是负责这个事务的 Transaction Coordinator 服务地址。

##### 获取 ProducerId

Kafka 实现事务需要依靠幂等性，而幂等性需要指定 ProducerId 。所以 Producer 在启动事务之前，需要向 Transaction Coordinator 服务申请 ProducerId。Transaction Coordinator 服务在分配 ProducerId 后，会将它持久化到事务 Topic。

##### 事务初始化

Producer 在接收到 ProducerId 后，需要先告诉 Transaction Coordinator 我要将数据发送到哪个分区。Transaction Coordinator 会将这些分区地址持久化到事务 Topic，并将这个事务标记为 Begin。

##### 发送消息

然后 Producer 才会真正的发送消息，这些消息与普通消息不同，它们会有一个字段，表示自身是事务消息。

这里需要注意下一种特殊的请求，提交消费位置请求，用于原子性的从某个 Topic 读取消息，并且发送消息到另外一个 Topic。我们知道一般是消费者使用消费组订阅 Topic，才会发送提交消费位置的请求，而这里是由 Producer 发送的。Producer 首先会发送一条请求，里面会包含这个消费组对应的分区（每个消费组的消费位置都保存在 __consumer_offset Topic 的一个分区里），Transaction Coordinator 服务会将分区持久化之后，发送响应。Producer 收到响应后，就会直接发送消费位置请求给 GroupCoordinator。

##### 发送提交请求

Producer 发送数据后，如果所有数据写入成功，就会向 Transaction Coordinator 发送一个事务提交请求。

##### 提交请求持久化

Transaction Coordinator 服务收到事务提交请求后，会先将提交信息持久化到事务 Topic 。持久化成功后，发送成功响应给 Producer。然后向该事务涉及到的所有分区发送事务提交请求。

> 读者可能有所疑问，在一般的二阶段提交中，协调者需要收到所有参与者的响应后，才能判断此事务是否成功，最后才将结果返回给客户。那如果 Transaction Coordinator 服务在发送响应给 Producer 后，还没来及向分区发送请求就挂掉了，那么 Kafka 是如何保证事务完成。因为每次事务的信息都会持久化，所以 Transaction Coordinator 服务挂掉重新启动后，会先从事务 Topic 加载事务信息，如果发现只有事务提交信息，却没有后来的事务完成信息，说明存在事务结果信息没有提交到分区。

##### 发送事务结果信息给分区

当一个分区收到事务提交的消息后才会提交数据，并且返回成功响应到 Transaction Coordinator。当 Transaction Coordinator 收到所有分区的成功响应后，会持久化一条 COMPLETE_COMMIT 的消息到事务 Topic。标识着事务完成。
