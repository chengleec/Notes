### Producer

<img src="/Users/licheng/Documents/Typora/Picture/image-20200704204625379.png" alt="image-20200704204625379" style="zoom:50%;" />

* KafkaProducer 首先将消息序列化，然后确定消息分区，最后发送给 RecordAccumulator 缓冲区中。
  * 指明 partition 的情况下，直接将指明的值直接作为 partiton 值；

  * 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；

  * 既没有 partition 值又没有 key 值的情况下，使用轮询算法。

* 缓冲区中有一个 ConcurrentHashMap，key 是 TopicPartition，Value 是一个 ProducerBatch 的队列。Message 会追加到相应的 ProducerBatch 队列中。 

  > ```java
  > private final ConcurrentMap<TopicPartition, Deque<ProducerBatch>> batches;
  > ```

* Sender 线程会从对应的 ProducerBatch 队列拉取消息，然后生成请求，通过 NetworkClient 发送出去。

### Comsumer Group

#### GroupCoordinator

Group Coordinator 是一个服务，kafka 集群中的每个节点在启动时都会启动这样一个服务，GroupCoordinator 的作用是用来存储Group 的相关元数据信息，管理组内成员，并将对应 Partition 的 offset 信息记录到 Kafka 内置 Topic `(__consumer_offsets)` 中。处理的请求类型主要有以下 8 种：

* `OffsetFetch`：查询 offset。
* `OffsetCommit`：提交 offset。
* `JoinGroup`：Consumer 加入 Group。
* `SyncGroup`：同步 Group 信息。
* `DescribeGroup`：返回 Group 中各个 member 的详细信息。
* `LeaveGroup`：Consumer 离开 Group。在什么情况下，Server 会收到 LEAVE_Group 的请求呢？
  * Consumer 调用 `unsubscribe()` 方法，取消了对所有 Topic 的订阅时；

  * Consumer 的心跳线程超时时，这时 Consumer 会主动发送 LEAVE_Group 请求；

  * 在 Server 端，如果在给定的时间没收到 Client 的心跳请求，这时候会自动触发 LEAVE_Group 操作。
* `HeartBeat`：心跳请求
* 对于 Server 端来说，它是 GroupCoordinator 判断一个 Consumer member 是否存活的重要条件，如果其中一个 Consumer 在给定的时间没有发送心跳请求，那么就会将这个 Consumer 从这个 Group 中移除，并执行 Rebalance 操作。
  
* 对于 Client 端而言，心跳请求是 client 感应 Group 状态变化的一个重要中介，比如：此时有一个新的 Consumer 加入到 Consumer Group 中了，这时候会进行 Rebalace 操作，Group 端的状态会发送变化，当 Group 其他 member 发送心跳请求，GroupCoordinator 就会通知 Client 此时这个 Group 正处于 Rebalance 阶段，让它们 Rejoin Group。

#### Rebalance

##### Rebalance 场景

* 消费者组成员个数发生变化，如新的消费者加入或者退出消费组。
* 订阅的 Topic 个数发生变化。
* 订阅的 Topic 分区数发生变化。

##### Rebalance 流程

* 组内所有 Consumer 向 GroupCoordinator 发送 JoinGroup 请求，上报订阅信息。GroupCoordinator 会将第一个加入的消费者定为 leader，将所有成员信息以及订阅信息发给 leader。

* leader 负责为组内所有成员指定分配方案 (Partition 轮询)，确定每个 consumer 都负责哪些 Topic 的哪些分区。leader 通过 SyncGroup 请求将分配方案发给 GroupCoordinator ，follower 通过 SyncGroup 请求发送一个空列表。

* GroupCoordinator 收到 leader 发送的请求后，会结果返回给发送了 SyncGroup 请求的 Consumer 实例。

### Consumer 消费数据流程

* 根据 Group id 获取 GroupCoordinator 的地址，加入 Consumer Group，然后获取要消费的 Topic-Partition 列表。

  Kafka 内部使用 `__Consumer_offsets` 来保存 Group 消费的 offset。默认情况下有 50 个分区，Group 消费情况要存储到哪一个 Partition 上，是根据 GroupId 与 `__Consumer_offsets` 分区数量做取模运算得出的。

  Consumer 根据 GroupId 获取到该 Group 属于哪个分区，分区 leader 就是该 GroupCoordinator 的地址。

* 向 GroupCoordinator 发送 `OffsetFetch` 请求来获取对应 Topic-Partition 的 commitedOffset。

  如果无法从 GroupCoordinator 获取消费过的 offset，Consumer 就会通过 auto.offset.reset 配置定义的策略设置一个新的 offset 作为 commitedOffset。auto.offset.reset 有三种策略：

  * latest：默认策略。获取 partition 中最新的一条 offset，也就是 LEO。

  * earliest：获取 Partition 的最早的一条 offset。

  * none：配置了该策略的话，如果没有从 GroupCoordinator 获取到 commitedOffset，就会抛异常。

* 向要消费那些的 Partition 的 leader 所在的 Broker 发送 Fetch 请求拉取数据。Fetch 请求时异步的，不会等待数据返回，也不会阻塞` poll() `方法的执行。发送 Fetch 请求是为了下一次的 `poll()` 可以尽快获取到数据，达到数据预取的效果。


* 消费数据，提交 offset。

  在 Consumer 类中，有 5 个方法可以提交 offset。同步提交和异步提交其实底层都是向 broker 发送 OFFSET_COMMIT 请求。不同的是同步的会等待请求返回，异步的不会等待请求返回。

  ```java
  //同步提交已经拉取回来的partition的offset
  public void commitSync();
  //同步提交指定topic-partition的指定offset
  public void commitSync(Map<TopicPartition, OffsetAndMetadata> offsets);
  //异步提交已经拉取回来的partition的offset
  public void commitAsync();
  //异步提交已经拉取回来的partition的offset，带上一个回调函数
  public void commitAsync(OffsetCommitCallback callback);
  //异步提交指定topic-partition的指定offset，带上一个回调函数
  public void commitAsync(Map<TopicPartition, OffsetAndMetadata> offsets, OffsetCommitCallback callback);
  ```

  如果 partition 是由 GroupCoordinator 分配并管理的，并且 Consumer 配置 enable.auto.commit 为 true，则在每次 poll 拉取数据之前，kafka 都会自动异步提交已经拉取过的 offset。该配置默认是开启的，自动提交的频率和 auto.commit.interval.ms 有关，该配置的默认值是 5000。
