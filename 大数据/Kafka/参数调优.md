#### Producer

```java
// 常规参数解析
Properties props = new Properties();
props.put("bootstrap.servers","localhost:9092");
props.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
props.put("buffer.memory",67108864);
props.put("batch.size",131072);
props.put("linger.ms",100);
props.put("max.request.size",10485760);
props.put("acks","1");
props.put("retries",10);
props.put("retry.backoff.ms",500);
KafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);
```

- buffer.memory：生产者可以用来缓冲等待发送到服务器的记录的内存的总字节数，简单说就是缓冲区大小。当我们发送数据的时候，会先缓冲起来再发。默认33554432(32M)，可以调大一点，比如536870912。
- batch.size：批处理大小(字节为单位)。发送消息并不是说来一条我就发一条，会一个批次一个批次的发，这有助于提高客户机和服务器的性能。这个参数决定了你的每个 Batch 要存放多少数据就可以发送出去了。默认16384。可以调大一点。
- linger.ms：一个Batch被创建之后，最多过多久，不管这个Batch有没有写满，都必须发送出去了。避免一个Batch迟迟凑不满，导致消息一直积压在内存里发送不出去的情况。
- max.request.size：最大请求大小，这个参数决定了每次发送给Kafka服务器请求的最大大小，同时也会限制你一条消息的最大大小也不能超过这个参数设置的值。默认2097152。
- retries 和 retries.backoff.ms：这两个参数决定了重试机制，也就是如果一个请求失败了可以重试几次，每次重试的间隔是多少毫秒。
- request.timeout.ms：配置控制客户端等待请求响应的最大时间量。如果在超时之前没有收到响应，客户端将在必要时重新发送请求，如果重试结束，则将失败请求。经验：跟超时时间有关的，都调大几倍。
- compression.type：设置压缩，压缩的好处不用多说，减少磁盘IO、减少存储所需空间等等。比如可以设置为snappy。
- ack：确认机制。
  *  0：表示 producer 从来不等待来自 broker 的确认信息。这个选择提供了最小的时延但同时风险最大。
  * 1：表示获得 leader replica 已经接收了数据的确认信息。这个选择时延较小同时确保了 server 确认接收成功。
  * -1：producer 会获得所有同步 replicas 都收到数据的确认，时延最大。
- min.insync.replicas：当生产者设置应答为 "all"(或“-1”) 时，此配置指定了成功写入的副本应答的最小数。如果没满足此最小数，则生产者将引发异常。
- replica.lag.time.max.ms：如果一个 Follow 落后太多，Leader 会将它从 ISR 中移除，落后太多意思是该 Follow 长时间没有向 leader 发送 fetch 请求，容许的最大时间为`replica.lag.time.max.ms`。默认值：10000。
- timeout.ms：控制服务器等待 follower 确认的最大时间量，以满足生产者使用 acks 配置指定的确认需求。如果在超时运行时未满足确认请求的数量，则将返回一个错误。这个超时是在服务器端测量的，不包括请求的网络延迟。建议调大一点。
- max.block.ms：控制了 KafkaProducer.send() 和 KafkaProducer.partitionsFor() 将会阻塞多长时间。由于缓冲区已满或元数据不可用，可以阻塞这些方法。建议调大一点此参数。

#### Broker

- message.max.bytes：服务器可以接收的一条消息的最大大小。
- zookeeper.session.timeout.ms：zk超时时间。关于timeout的都要调大一点。
- num.replica.fetchers：从源复制消息的线程数量。增加这个值可以增加follower broker中I/O并行度。可以略微调大点。
- log.flush.interval.messages：任何主题中的消息在刷新到磁盘之前被保存在内存中的最大时间消息数量
- log.flush.interval.ms：消息在刷新到磁盘之前被保存在内存中的最大时间

#### Consumer

- fetch.min.bytes :每次 fetch 请求时，Server 应该返回的最小字节数。如果没有足够的数据返回，请求会等待，直到足够的数据才会返回。
- max.partition.fetch.bytes：每次从单个分区中拉取的消息最大数量(单位byte),建议调大点，比如5242880。
- auto.commit.enable：自动提交偏移量，consumer 所 fetch 的消息的 offset 将会自动的同步到 Kafka。
- request.timeout.ms：会话超时时间。有关 timeout 的都调大一点
- session.timeout.ms：请求超时时间。有关 timeout 的都调大一点
- heartbeat.interval.ms：每次心跳的间隔时间。心跳被用来确保消费者的会话保持活跃，并在新消费者加入或离开群体时促进再平衡。值的设置必须低于session.timeout.ms，但通常应该设置不超过该值的1/3。它可以调整更低，以控制预期时间的正常重新平衡。
- receive.buffer.bytes：读取数据的缓冲区大小。可以调大点。