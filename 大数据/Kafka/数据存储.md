#### 存储文件结构

<img src="/Users/licheng/Documents/Typora/Picture/image-20200501202138175.png" alt="image-20200501202138175" style="zoom:67%;" />

* Topic： 可以理解为一个消息队列的名字。
* Partition：Topic 物理上的分组，一个 Topic 可以分为多个 Partition，每个 Partition 是一个有序的队列，每个 partion 中的数据都是不同的。
* segment：Partition 物理上由多个 segment 组成。
* offset：每个 Partition 都由一系列有序的、不可变的消息组成，这些消息被连续的追加到 Partition 中，Partition 中的每个消息都有一个连续的序列号叫做 offset，用于 Partition 唯一标识一条消息。
* message：每个 segment 文件中实际存储的每一条数据就是 message，kafka 文件中的最小存储单位。

#### Partion 分区

* 为什么要分区

  如果不分区，每个 Topic 的消息只存在一个 broker 上，那么所有的消费者都是从这个 broker 上消费消息，那么单节点的 broker 成为性能的瓶颈，如果有分区的话，生产者发过来的消息分别存储在各个 broker 不同的 Partition 上，这样消费者可以并行的从不同的 broker 不同的 Partition 上读消息，实现了水平扩展。

* 分区策略
  * 如果指定 key，就按照 key 的 hashcode 对分区数取模获取分区编号。
  * 如果没有指定 key，就使用轮询策略。

* 分区文件下的存储内容

  其实每个分区下保存了很多文件，而概念上我们把他叫 segment，即每个分区文件都是由多个 segment 构成的，其中 index（索引文件），log（数据文件），time index（时间索引文件）统称为一个 segment。

  <img src="/Users/licheng/Documents/Typora/Picture/image-20200501202620542.png" alt="image-20200501202620542" style="zoom:67%;" />

* 为什么有了 Partition 还需要 segment ？

  如果不引入 segment，那么一个 Partition 只对应一个 log 文件，随着消息的不断发送这个文件不断增大，由于 kafka 的消息不会做更新操作，都是顺序写入的，如果做消息清理的时候只能删除文件的前面部分删除，不符合 kafka 顺序写入的设计，如果多个 segment 的话那就比较方便了，直接删除整个文件即可保证了每个 segment 的顺序写入。

#### segment 存储

* 命名规则：Partition 的第一个 segment 从 0 开始，后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset。
* index 文件：文件中保存 message 的 offset 和对应 message 在 log 文件中的物理地址。
* log 文件：log 数据文件中并不是直接存储数据，而是由许多的 message 组成，message 包含了实际的消息数据。   
* timestamp 文件：Kafka 从 0.10.0.0 版本起，为分片日志文件中新增了一个 .timeindex 的索引文件，可以根据时间戳定位消息。

message 结构

| 关键字 | 说明                                                         |
| ----------------------- | ------------------------------------------------------------ |
| 8 byte offset           | 在 parition 内的每条消息都有一个有序的 id 号，这个 id 号被称为偏移量 (offset),它可以唯一确定每条消息在 parition 内的位置。即 offset 表示 partiion 的第多少 message。 |
| 4 byte  message size    | message 大小。                                                |
| 4 byte  CRC32           | 用 crc32 校验 message。                                       |
| 1 byte  “magic”         | 表示本次发布 Kafka 服务程序协议版本号。                       |
| 1 byte  “attributes”    | 表示为独立版本、或标识压缩类型、或编码类型。                  |
| 4 byte  key length      | 表示 key 的长度,当 key 为 -1 时，K  byte key 字段不填。       |
| K byte  key             | 可选。                                                        |
| value  bytes payload    | 表示实际消息数据。                                           |

#### 消费者如何通过 offset 查找 message？

* 查找 segment file：segment 文件都是以起始偏移量命名和排序的，只要根据 offset  二分查找文件列表，就可以快速定位到具体文件。 
* 通过 segment file 查找 message：通过 index 文件定位其物理偏移地址，最后通过 log 文件找到对应的 message。

#### 过期日志删除策略

记录只会被 append 到 segment 中，不会修改。清除过期日志时直接删除一个或者等多个 segment。

* 基于时间：默认 168 小时后就被删除，参数：log.retention.hours。

* 自定义设置 Partition size：

  log.segment.bytes：单个日志分片大小

  log.retention.bytes：日志文件总大小，默认未开启 (即无穷大)