### 介绍

Apache Kafka 是一个分布式的消息发布-订阅系统，能够支撑海量数据的数据传递。Kafka 具有分区机制和副本机制。可以保证在较高的处理速度的同时，又能保证数据处理的低延迟和数据的可靠性。

Kafka 的优势在于：

* 高吞吐低延迟：Kafka 通过批量发送数据、分区机制与顺序写磁盘实现了高吞吐量。
* 高可用：Kafka 是一个具有分区机制、副本机制的分布式消息系统。
* 可扩展：Kafka 消息系统支持集群规模的热扩展。
* 消息有序：Kafka 可以保证一个 Partition 中的数据是有序的。

Kafka 缺点：

* 由于是批量发送，数据并非真正的实时；
* 仅支持同一分区内消息有序，无法实现全局消息有序；
* 监控不完善，需要安装插件；
* 依赖zookeeper进行元数据管理；

### kafka基本概念

#### Messages

Kafka 的基本数据单元被称为 message(消息)，为减少网络开销，提高效率，多个消息会被放入同一批次 (Batch) 中后再写入。

#### Topic

<img src="/Users/licheng/Documents/Typora/Picture/image-20200501204506324.png" alt="image-20200501204506324" style="zoom:67%;" />

Kafka 的消息通过 Topics 进行分类，一个 Topic 可以被分为若干个 Partitions，消息以追加的方式写入 Partition 中。

#### Producer

生产者负责创建消息。一般情况下，生产者在把消息均衡地分布到在主题的所有分区上，而并不关心消息会被写到哪个分区。

#### Consumer

消费者负责消费消息。消费者可以订阅一个或者多个主题，并按照消息生成的顺序来读取它们。

一个 Partition 只能被同一个消费者群组里面的一个消费者读取，但可以被不同消费者群组中所组成的多个消费者共同读取。多个消费者群组中消费者共同读取同一个主题时，彼此之间互不影响。

#### Broker

一个独立的 Kafka 服务器被称为 Broker。Broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Broker 还会响应消费者的消费请求，返回请求的数据。

#### Offset

offset 是一个 long 型数值，唯一对应一条 message。记录着 Producer 的发送数据位置和 consumer 消费数据位置。

Kafka 0.9 开始将消费端的位移信息保存在集群的内部 Topic (`__consumer_offsets`) 中，该主题默认为 50 个分区，每条日志项的格式都是：<TopicPartition, OffsetAndMetadata>，其 key 为主题分区主要存放主题、分区以及消费组信息，value 为 OffsetAndMetadata 对象主要包括位移、位移提交时间、自定义元数据等信息。

只有消费组往 kafka 中提交 offset 才会往这个主题中写入数据，如果消费端将消费位移信息保存在外部存储，则不会有消费位移信息，可以通过 kafka-console-consumer.sh 脚本查看主题消费位移信息。

#### HW &  LEO

<img src="/Users/licheng/Documents/Typora/Picture/image-20200617173415288.png" alt="image-20200617173415288" style="zoom:50%;" />

* HW：High Watermark，是一个比较特殊的 offset 标记，消费端消费时只能拉取到小于 HW 的消息而 HW 及之后的消息对于消费者来说是不可见的，该值由 leader 管理，**当 ISR 集合中的全部 follower 都拉取到 HW 指定消息之后，leader 会将 HW 值加 1**，即指向下一个 offset 位移，这样可以保证 HW 之前消息的可靠性。
* LEO：Log End Offset，表示当前副本最新消息的下一个 offset，所有副本都存在这样一个标记，如果是 leader，当生产端往其追加消息时，会将其值加 1。当 follower 从 leader 成功拉取到消息时，其值也会增加。

### Replica 机制

Kafka 每个 Topic 的 Partition 有多个副本，Kafka 集群中一个 Broker 失效情况下仍然可以保证服务可用。多副本机制中会有一个副本称为 leader，处理 Partition 的所有读写请求，其他都为 follower，定期地去同步 leader 上的数据。

leader 会负责维护 ISR 列表 (In-Sync Replicas)，列表中保存的是所有与 leader 状态同步的 follower。如果 follower 中的消息数量远落后于 leader 的消息数量或者 follow 长时间没有向 leader 发送 fetch 请求，该 follower 将会被从 ISR 列表中移除，直到满足条件才会被再次加入。

相关参数：

* `Replica.lag.max.messages` ：落后 msg 条数，默认值：4000。
* `Replica.lag.time.max.ms `：超时时间，默认值：10000。

#### leader epoch 机制

leader epoch 使用一个键值对 <epoch, offset> 表示，其中 epoch 表示 leader 的版本号，从 0 开始，当 leader 每变更一次就会加 1，offset 表示该 epoch 版本的 leader 写入第一条消息的位置。

比如 <0,0> 表示第一个主副本从位移 0 开始写入消息，<1,100> 表示第二个 leader 版本号为 1 并从位移 100 开始写入消息。

leader 会将该信息保存在缓存中并定期写入到 checkpoint 文件中，每次发生主副本切换都会去从缓存中查询该信息。

#### Partition Leader 选举机制

##### OfflinePartitionLeaderSelector

leader 掉线时触发。选举流程：

* 如果 ISR 中至少有一个副本是存活的，那么从该 Partition 存活的 ISR 中选举第一个副本作为新的 leader，存活的 ISR 作为新的 ISR；
* 如果允许 unclean elect，从存活的、不在 ISR 中的副本中选出一个副本作为新的 leader 和新的 ISR 集合；
* 如果禁止 unclean elect 或者  Partition 分配的副本没有存活的，那么就抛出 NoReplicaOnlineException 异常。

##### ReassignedPartitionLeaderSelector

ReassignedPartitionLeaderSelector 是在 Partition 副本迁移后，副本同步完成 (RAR 都处在 ISR 中) 后触发的，leader 选举流程：

* leader 选择存活的 RAR 中的第一个副本，此时 RAR 都在 ISR 中了；

* 新的 ISR 是所有存活的 RAR 副本列表。

##### PreferredReplicaPartitionLeaderSelector

PreferredReplicaPartitionLeaderSelector 是最优 leader 选举，选择 AR 中的第一个副本作为 leader，前提是该 Replica 在是存活的、并且在 ISR 中，否则会抛出 StateChangeFailedException 的异常。

##### ControlledShutdownLeaderSelector

ControlledShutdownLeaderSelector 是在处理 Broker 下线时调用的 leader 选举方法，它会选举 ISR 中第一个没有正在关闭的 Replica 作为 leader，否则抛出 StateChangeFailedException 异常。

#### 副本写入策略

当 Producer 向 leader 发送数据时，可以通过`request.required.acks `参数来设置数据可靠性的级别：

* acks = 0：Producer 发出消息即完成发送，无需等待来自 Broker 的确认。这种情况下数据传输效率最高，但是数据可靠性是最低的。
* acks = 1：Producer 要等待分区 leader 成功收到数据并收到确认即认为发送成功。如果 leader 宕机，则会丢失数据。
* acks = -1（ALL）：Producer 需要等待 ISR 列表中所有成员都确认接收数据后才算一次发送完成，可靠性最高，延迟也较大。

### 高吞吐低延迟原理

#### 批量发送

发送消息并不是说来一条我就发一条，会一个批次一个批次的发，这有助于提高客户机和服务器的性能。

参数设置：`max.Partition.fetch.bytes `，每次从单个分区中拉取的消息最大数量 (单位byte)。

#### Partition 机制

kafka 通过 Partition 实现了并行处理和水平扩展。不同 Partition 可处于不同的 Broker（节点），可以充分利用多机资源。

#### 顺序写磁盘

Kafka 使用了基于日志结构 (log-structured) 的数据格式，即只能在每个分区尾部追加数据 (append-only)，而不允许随机“跳到”某个位置开始写入，故此实现了顺序写入。

同时为了减少磁盘写入的次数，Broker 会将消息暂时缓存到 buffer 中，当消息的个数 (或大小) 达到一定阀值时,再 flush 到磁盘。这样减少了磁盘 IO 调用的次数。对于 kafka 而言，较高性能的磁盘，将会带来更加直接的性能提升。

#### 零拷贝

Kafka 所有数据的写入和读取都是通过零拷贝来实现的。

### Kafka Shell 命令

* 以后台方式启动kafka服务
  `kafka-server-start.sh -daemon /home/hduser/kafka_2.12-2.3.1/config/server.properties`

* 创建Topic

  ```shell
  # --Topic test  Topic名称
  # --Partitions 3 分区数量并行度
  # --Replication-factor 3 副本数量
  # --zookeeper  zk地址
  kafka-Topics.sh --create --Topic userBehavior --Partitions 5 --Replication-factor 3 --zookeeper master01:2181,master02:2181,slave01:2181,slave02:2181,slave03:2181
  ```

* 查看Topic
  `bin/kafka-Topics.sh --describe --bootstrap-server localhost:9092`

* 创建生产者

  ```shell
  # localhost表示从本地 9092 端口 push
  kafka-console-Producer.sh --Topic userBehavior --Broker-list localhost:9092
  ```

* 创建消费者

  ```shell
  # localhost表示从本地9092端口pull，可以用集群中任意一台Broker的9092端口，只要连上了zookeeper
  kafka-console-consumer.sh --Topic weblogs --bootstrap-server localhost:9092  --from-beginning
  ```

  

    

