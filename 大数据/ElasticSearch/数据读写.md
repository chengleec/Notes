### 数据读取过程

客户端发送请求到协调节点（ElasticSearch 的任意节点都可以作为协调节点接受请求），当协调节点接受到请求后通过 `__routing` 字段进行哈希路由，使用随机轮询算法将请求转发到对应的 Node (`__routing` 默认值是文档的 id，也可以采用自定义值，比如用户 id)。

> `shard = hash(_routing) % (num_of_primary_shards)`
>
> 随机轮询算法：随机选择一个节点作为开始位置的 index，此后每次选择下一个节点来处理请求，即 (index+1)%size。

节点返回 document 给 coordinate node。协调节点返回 document 给客户端。

> 如果想查询最新的数据，可以设置 `_preference = primary`，这样可以保证查询到的都是最新的数据。

#### 数据搜索过程

ES 最强大的是做全文检索，比如根据 `java` 关键词来搜索，ES 会将包含 `java` 的 `document` 给搜索出来。

根据关键词搜索的时候，因为不带 `_routing` 字段，在查询的时候因为不知道要查询的数据具体在哪个分片上，所以整个过程分为 2 个步骤：

* 分发：请求到达协调节点后，协调节点将查询请求分发到每个分片上。
* 聚合：协调节点搜集到每个分片上查询结果 (`doc id` )，将查询的结果进行排序。
* 拉取：协调节点根据 `doc id` 去各个节点上拉取实际的文档数据，最终将数据返回给用户。

如果带 `_routing` 字段查询，查询的时候，可以直接根据 `_routing` 信息定位到某个分片查询，不需要查询所有的分配，经过协调节点排序。

### 数据写入过程

客户端发送请求到协调节点（ElasticSearch 的任意节点都可以作为协调节点接受请求），当协调节点接受到请求后通过 `_routing` 字段找到对应的 primary shard，`_routing` 默认值是文档的 id，也可以采用自定义值，比如用户 id。

`shard = hash(_routing) % (num_of_primary_shards)`

并将请求转发给 primary shard，primary shard 完成写入后，将数据发送给各个副本， 副本分片执行写入操作后将结果返回给主分片。主分片再将请求返回给协调节点。大致流程如下图：

<img src="/Users/licheng/Documents/Typora/Picture/image-20200620165454348.png" alt="image-20200620165454348" style="zoom: 50%;" />

#### 数据写入 Shard

<img src="/Users/licheng/Documents/Typora/Picture/image-20200716154108154.png" alt="image-20200716154108154" style="zoom:67%;" />

* 数据写入到 Memory Buffer，同时写入到数据到 Translog Buffer。

* 每隔 1s 数据从 Memory Buffer 中 Refresh 到 FileSystemCache 中，生成一个新的 Segment 文件，一旦生成 Segment 文件，就能通过索引查询到了。Refresh 完，清空 Memory Buffer。

  > 由于 Refresh 默认间隔为 1s 中，因此会产生大量的小 Segment，为此 ElasticSearch 会运行一个任务检测当前磁盘中的 Segment，对符合条件的 Segment 进行合并操作，减少 Segment 个数，提高查询速度，降低负载。
  >
  > 不仅如此，**merge 过程也是文档删除和更新操作后，旧的 doc 真正被删除的时候。**合并过程中，回去查询 `.del` 文件中该文档是否存在，如果存在，就删除，不会进行合并操作。

* 每隔 5s，Translog 从 Buffer 提交到磁盘中。

* 每 30 分钟或当 Translog 达到一定大小 (由`index.Translog.flush_threshold_size`控制，默认512mb)，ElasticSearch 会触发一次 flush 操作，此时 ElasticSearch 会先执行 Refresh 操作将 Memory Buffer 中的数据生成 Segment，然后调用 commit 方法将 FileSystemCache 中的 Segment 刷新到磁盘，并删除 Translog。此时数据就完成了持久化。

在 commit 时, 如果操作为删除，生成一个 `.del` 文件, 将该 document 标记位 `deleted`，那么搜索的时候根据 `.del` 文件就知道这个 document 是否被删除了。

在 commit 时, 如果为更新操作，就是将原来的 document 标识为 `deleted` 状态，然后新写入一条数据。