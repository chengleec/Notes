### HBase 架构

<img src="/Users/licheng/Documents/Typora/Picture/image-20200501152635841.png" alt="image-20200501152635841"  />

HBase 中的每张表都通过行键按照一定的范围被分割成多个子表（HRegion），**默认一个 HRegion 超过 256M 就要被分割成两个**，由 HRegionServer 管理，管理哪些 HRegion 由 HMaster 分配。

HRegionServer 存取一个子表时，会创建一个 HRegion 对象，然后对表的每个列族 (Column Family) 创建一个 Store 实例，每个 Store 都会有 0 个或多个 StoreFile 与之对应，每个 StoreFile 都会对应一个 HFile，HFile 就是实际的存储文件。因此，**一个 HRegion 有多少个列族就有多少个 Store**。此外，每个 HRegion 还拥有一个 MemStore 内存缓存实例。

#### HDFS

HDFS 为 HBase 提供底层数据存储服务（元数据和表数据都存储在HDFS中），HDFS 数据多副本机制能保证HBase 的高可靠性，同时提供对 HBase 高可用（Hlog 存储在 HDFS）的支持。

#### HMaster：

* 维护集群的元数据信息，维护集群负载均衡。处理 schema 更新请求。
* 管理 HRegionServer，为 RegionServer 分配 Region，当 RegionSever 失效的时候，协调对应 Hlog 的拆分，将失效的 Region 分配到正常的 RegionServer 上。
* HDFS 上的垃圾文件回收（标记为删除的且经过 major compact 的文件）

#### HRegionServer：

* 直接对接来自客户端的读写请求，比如表的增删改查数据，和 HDFS 交互，存取数据。

* 管理 HMaster 为其分配的 Region，负责 Region 变大以后的拆分以及 Storefile 的合并工作。

#### Zookeeper：

* 实现 HA，Zookeeper 保存 HMaster 的地址和 backup-Master 地址，Zookeeper 能保证集群中只有1个 Master 在运行，如果 Master 异常，会通过竞争机制选举新的 Master。
* 管理 HRegionServer，监控 RegionServer 的状态。当 RegionSevrer 有异常的时候，通过回调的形式通知Master 关于 RegionServer上下限的信息。

* Zookeeper 存储元数据的统一入口地址 (znode:/hbase/meta-Region-server)，读取数据所需要的元数据表在Zookeeper 上。

#### MemStore

MemStore 是内存缓冲区，HBase 写入数据的时候会先停留在 MemStore 中，达到一定的时候才会 flush 到StoreFile 中。

* 为什么要有 MemStore 的存在呢？
  * 可以提高写的性能，减少磁盘IO次数。
  * 可以进行排序。HBase 写入到 HDFS 上的数据是需要按照 RowKey 进行排序的，而 HBase 是随机的读写，因此 HBase 通过 memstore 在持久化到 HDFS 之前完成排序，然后再快速的顺序写入 HDFS。
  * 优化数据的存储。比如一个记录添加之后马上被删除了，在 flush 的时候就可以直接不把这个数据写到HDFS 中。

* 触发 flush 的操作。

  * Region：当 MemStore 的大小达到`hbase.hRegion.memstore.flush.size`大小的时候会触发刷盘，默认 128 M。
  * Hlog：当 Hlog 达到一定大小时会触发 flush 操作,（如果Hlog很大，恢复的时候就需要很长时间)。 相关参数：`hbase.Regionserver.hlog.blocksize` * `hbase.Regionserver.maxlogs`

  * 全局内存控制：当 memstore 容量达到整个堆的 40% 的时候，会触发 flush 的操作。参数配置：`hbase.Regionserver.global.memstore.size`。

#### Hlog

Hlog 是 HBase 实现 WAL（Write ahead log）方式产生的日志信息，内部是一个简单的顺序日志。数据到达 Region 会先写入WAL，然后再被加载到 MemStore 中的。每个 RegionServer 对应 1 个 Hlog，所有对于该RegionServer 的写入都被记录到 Hlog 中。Hlog 功能就是为了保证数据安全。当 RegionServer 出现问题的时候，能跟进 Hlog 来做数据恢复。

> HLog 文件就是一个普通的 Hadoop Sequence File。

<img src="/Users/licheng/Documents/Typora/Picture/image-20200501175908470.png" alt="image-20200501175908470" style="zoom:67%;" />

* Hlog = Hlogkey + WALEdit。Hlogkey = sequenceid + timestamp + cluster ids + Region name + table name 等组成，WALEdit 是由一系列的 KeyValue 组成，即对应 HFile 中的 KeyValue 值。
* sequenceid 是一个自增序列号，Region 的数据恢复和 Hlog 过期清除都要依赖它。
  * 当 RegionServer 出现故障的时候，需要对 Hlog 进行回放来恢复数据。回放的时候会读取 Hfile 的sequenceid 和 Hlog 中的 sequenceid 进行比较，小于的就直接忽略，大于等于的就进行重做。回放完成后，就完成了数据的恢复工作。
  * Hlog 的过期依赖于对 sequenceid 的判断。HBase 会将 Hlog 的 sequenceid 和 Hfile 最大的 sequenceid 进行比较，如果该 Hlog 文件中的 sequenceid 比 Hfile 文件中的 sequenceid 都要小，那么这个 Hlog 就过期了，过期了以后，对应 Hlog 会被移动到 oldWAL 目录。

* WAL 滚动：WAL 是一个环状的滚动日志结构，这样可以保证写入效果最高并且保证空间不会持续变大。

  触发滚动的条件：

  * WAL 的检查间隔：`hbase.Regionserver.logroll.period`。默认一小时，通过 sequenceid，把当前 WAL 的操作和 Hfile 对比，看哪些操作已经被持久化了。就被移动到 oldWAL 目录中。

  * 当 WAL 所占的空间大于或等于下面的阈值时

    `hbase.Regionserver.hlog.blocksize` * `hbase.Regionserver.logroll.multiplier` 

    > blocksize 是存储系统的块大小，如果你是基于HDFS，只要设定为 HDFS 的块大小即可。
    >
    > multiplier 是一个百分比，默认 0.95，即 WAL 所占的空间大于或者等于 95% 的块大小，就被归到oldWAL 文件中

* oldWAL 何时删除：HMaster 会定期的去清理这个文件，如果当这个 WAL不需要作为用来恢复数据的备份，那么就可以删除。两种情况下，可能会引用 WAL 文件，此时不能删除：
  * TTL进程：该进程会保障 WAL 文件存活到 `hbase.master.logcleaner.ttl`定义的超时时间为止，默认10分钟。
  * 备份机制：如果你开启了备份机制 Replication（把一个集群的数据实时备份到里另一个集群），那么HBase 要保障备份集群已经完全不需要这个文件了。

#### StoreFile 和 Hfile

* StoreFile 是对 HFile 进行了轻量级的包装。HFile 是实际数据的存储。

* HFile包括：①Data：数据块②Meta：元数据块③Fileinfo：文件信息④DataIndex：Data 块索引信息⑤MetaIndex：Meta 块索引信息⑥Trailer：存储了 Fileinfo Dataindex Metaindex 的偏移值。

### 数据模型

* RowKey：RowKey 是用来检索记录的主键。访问 HBase table 中的行，只有三种方式：
  * 通过单个 row key 访问
  * 通过 row key 的  range（正则）
  * 全表扫描
* ColumnFamily：HBase 通过列族划分数据的存储，列族下面可以包含任意多的列，实现灵活的数据存取。
* TimeStamp：在HBase 中使用不同的 TimeStamp 来标识相同 RowKey 行对应的不同版本的数据。

### RowKey 设计原则

* RowKey 唯一原则：在设计上保证其唯一性。

* RowKey 长度原则：越短越好，不要超过16个字节

  * 数据的持久化文件 HFile 中是按照 (Key,Value) 存储的，如果 RowKey 过长，会极大影响 HFile 的存储效率！
  * MemStore 将缓存部分数据到内存，若 RowKey 字段过长，内存的有效利用率就会降低，就不能缓存更多的数据，从而降低检索效率。

* RowKey 散列原则：让数据均匀分配到每个 RegionServer 上

  * 将 RowKey 的高位作为散列字段，由程序生成，低位放时间字段，提高数据均衡分布在每个 RegionServer 实现负载均衡的几率。

  * 反转：反转固定长度或者数字格式的 RowKey

    > 以手机号为RowKey，可以将手机号反转后的字符串作为 RowKey，从而避免诸如139、158之类的固定号码开头导致的热点问题。

### 预分区

创建表的时候多创建一些 Region。

* 原因：HBase 在创建表的时候，会自动为表分配一个 Region。但是创建新表后，往往是需要往表里导入大量的数据。这样大量的操作就同时集中在了一个 RegionServer 上，也有了热点问题。而且 Region 达到一定阈值会进行 Split，原始只有一个 Region，却导入那么多的数据，这样就会导致大量的 Split 操作。

* 实现：通过 SPLITS 或者 SPLITS_FILE 可以在创建表的时候指定分区。

  * `create 'test','info',SPLITS => ['20180201000','20180401000','20180601000']`

  * `create 'test1','info',SPLITS_FILE => '/home/split.txt'`（split.txt 中保存着分区信息）

### HBase 与 ElasticSearch 区别

ES 更适合全文检索，因为他底层基于倒排索引，可以根据搜索词快速找到相应的文档。

HBase 是列式存储，可以存储海量的数据。它更适合基于 RowKey 做简单的查询，不适合做复杂的查询